{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SG_betha.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN/DLjkF/8L2qaLpCSxFYqi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alenacode/SG_MMM2020/blob/master/SG_betha.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqbE0UZ-XoR8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "67277b74-06a6-4f37-93a1-f9301414c99b"
      },
      "source": [
        "# IMPORTING LIBRARIES\n",
        "# multivariate multi-step encoder-decoder lstm \n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from numpy import array, hstack, vstack\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import RepeatVector, LSTM, Dense, TimeDistributed\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# PREPARING OF INPUT DATA\n",
        "# get configurations from dir\n",
        "def get_data():\n",
        "    configs = []\n",
        "    for E in np.arange(-52, 53, +4):\n",
        "        with open(\"data/\" + str(E) + \".dat\", \"r\") as sample:\n",
        "            lattice = []\n",
        "            for line in sample:\n",
        "                lattice = [int(x) for x in line.split()]\n",
        "                configs.append(lattice)\n",
        "    return vstack(configs)\n",
        "\n",
        "# split a multivariate sequence into samples\n",
        "def split_sequences(dataset, num_of_timestamps, num_of_predictions):\n",
        "    X, Y = list(), list()\n",
        "    for i in range(len(dataset)):\n",
        "        # find the end of this pattern\n",
        "        end_ix = i + num_of_timestamps\n",
        "        out_end_ix = end_ix + num_of_predictions\n",
        "        \n",
        "        # check if we are beyond the dataset\n",
        "        if out_end_ix > len(dataset):\n",
        "            break\n",
        "        \n",
        "        # gather input and output parts of the pattern\n",
        "        seq_x, seq_y = dataset[i:end_ix], dataset[end_ix:out_end_ix]\n",
        "        X.append(seq_x)\n",
        "        Y.append(seq_y)\n",
        "    return array(X), array(Y)\n",
        "\n",
        "# horizontally stack columns\n",
        "data = get_data()\n",
        "print(\"Received data\")\n",
        "\n",
        "# choose a number of time steps (1 - сколько мы будем брать конфигураций для каждого шага LSTM, \n",
        "#\t\t\t\t\t\t\t\t 2 - на сколько шагов вперед хотим предсказать)\n",
        "num_of_timestamps, num_of_predictions = 3, 2\n",
        "\n",
        "# covert into input/output\n",
        "X, Y = split_sequences(data, num_of_timestamps, num_of_predictions)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.3, random_state = 0)\n",
        "features = X_train.shape[2]\n",
        "print(\"Splitted sequences to X_train, X_test, Y_train, Y_test\")\n",
        "\n",
        "# DEFINING & TRAINING THE MODEL\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(LSTM(32, activation = 'tanh', input_shape = (num_of_timestamps, features)))\n",
        "model.add(RepeatVector(num_of_predictions))\n",
        "model.add(LSTM(32, activation = 'tanh', return_sequences = True))\n",
        "model.add(TimeDistributed(Dense(features)))\n",
        "model.compile(optimizer = 'adam', loss = 'mse')\n",
        "\n",
        "# fit model and get loss\n",
        "model.fit(X_train, Y_train, epochs = 270, verbose = 0)\n",
        "print(\"Trained the model\")\n",
        "loss = model.evaluate(X_test, Y_test, verbose = 0)\n",
        "print(\"Test loss:\", loss)\n",
        "\n",
        "# PREDICTION\n",
        "# demonstrate prediction\n",
        "prediction = model.predict(X_test)\n",
        "prediction = array([-1 if i <= -0.5 else 1 for i in prediction.ravel()])\n",
        "\n",
        "# visualize (6 configs)\n",
        "plt.style.use('ggplot')\n",
        "plt.figure(figsize=(20, 7))\n",
        "plt.plot(Y_test.ravel()[:216], label=\"Real value\")\n",
        "plt.plot(prediction.ravel()[:216], label=\"Predicted value\")\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Received data\n",
            "Splitted sequences to X_train, X_test, Y_train, Y_test\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}